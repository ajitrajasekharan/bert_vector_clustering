{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Set up environment**"
      ],
      "metadata": {
        "id": "HBM7lKLZG3uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0 transformers==4.19.1 sacremoses==0.0.53"
      ],
      "metadata": {
        "id": "m0RsXkue3W-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Setup code**"
      ],
      "metadata": {
        "id": "jFIU70yGHDia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import *\n",
        "import operator\n",
        "from collections import OrderedDict\n",
        "import sys\n",
        "import traceback\n",
        "import argparse\n",
        "import string\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "#DEFAULT_MODEL_PATH='bert-large-cased'\n",
        "#DEFAULT_MODEL_PATH='bert-base-cased' #works best for names\n",
        "#DEFAULT_MODEL_PATH='bert-base-uncased'\n",
        "DEFAULT_MODEL_PATH='./'\n",
        "DEFAULT_TO_LOWER=False\n",
        "DEFAULT_TOP_K = 20\n",
        "ACCRUE_THRESHOLD = 1\n",
        "\n",
        "def init_model(model_path,to_lower):\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    print(\"******* MODEL[path] is:\",model_path,\" lower casing is set to:\",to_lower)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_path,do_lower_case=to_lower)\n",
        "    model = BertForMaskedLM.from_pretrained(model_path)\n",
        "    #tokenizer = RobertaTokenizer.from_pretrained(model_path,do_lower_case=to_lower)\n",
        "    #model = RobertaForMaskedLM.from_pretrained(model_path)\n",
        "    model.eval()\n",
        "    return model,tokenizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def perform_task(model,tokenizer,top_k,accrue_threshold,text,patched):\n",
        "    text = '[CLS] ' + text + ' [SEP]' \n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Create the segments tensors.\n",
        "    segments_ids = [0] * len(tokenized_text)\n",
        "\n",
        "    print(tokenized_text)\n",
        "\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(tokens_tensor, segments_tensors)\n",
        "        for i in range(len(tokenized_text)):\n",
        "                #if (i != 0 and i != len(tokenized_text) - 1):\n",
        "                #    continue\n",
        "                results_dict = {}\n",
        "                masked_index = i\n",
        "                neighs_dict = {}\n",
        "                if (patched):\n",
        "                    for j in range(len(predictions[0][0][0,masked_index])):\n",
        "                        if (float(predictions[0][0][0,masked_index][j].tolist()) > accrue_threshold):\n",
        "                            tok = tokenizer.convert_ids_to_tokens([j])[0]\n",
        "                            results_dict[tok] = float(predictions[0][0][0,masked_index][j].tolist())\n",
        "                        tok = tokenizer.convert_ids_to_tokens([j])[0]\n",
        "                        if (tok in tokenized_text):\n",
        "                            neighs_dict[tok] = float(predictions[0][0][0,masked_index][j].tolist())\n",
        "                else:\n",
        "                    for j in range(len(predictions[0][0][masked_index])):\n",
        "                        if (float(predictions[0][0][masked_index][j].tolist()) > accrue_threshold):\n",
        "                            tok = tokenizer.convert_ids_to_tokens([j])[0]\n",
        "                            results_dict[tok] = float(predictions[0][0][masked_index][j].tolist())\n",
        "                        tok = tokenizer.convert_ids_to_tokens([j])[0]\n",
        "                        if (tok in tokenized_text):\n",
        "                            neighs_dict[tok] = float(predictions[0][0][masked_index][j].tolist())\n",
        "                k = 0\n",
        "                sorted_d = OrderedDict(sorted(results_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
        "                print(\"********* Top predictions for token: \",tokenized_text[i])\n",
        "                for index in sorted_d:\n",
        "                    if (index in string.punctuation or index.startswith('##') or len(index) == 1 or index.startswith('.') or index.startswith('[')):\n",
        "                        continue\n",
        "                    print(index,round(float(sorted_d[index]),4))\n",
        "                    k += 1\n",
        "                    if (k > top_k):\n",
        "                        break\n",
        "                print(\"********* Closest sentence neighbors in output to the token :  \",tokenized_text[i])\n",
        "                sorted_d = OrderedDict(sorted(neighs_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
        "                for index in sorted_d:\n",
        "                    if (index in string.punctuation or index.startswith('##') or len(index) == 1 or index.startswith('.') or index.startswith('[')):\n",
        "                        continue\n",
        "                    print(index,round(float(sorted_d[index]),4))\n",
        "                print()\n",
        "                print()\n",
        "                #break\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ufTuOUHi3KQO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Load model of choice once** "
      ],
      "metadata": {
        "id": "VkrTX3mc7fik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = \"bert-base-cased\"\n",
        "model = \"ajitrajasekharan/biomedical\"\n",
        "tolower=False\n",
        "model,tokenizer = init_model(model,tolower)"
      ],
      "metadata": {
        "id": "q6H8--aO7iIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Modify input and execute for results**\n",
        "\n",
        "_**Note:** Results shown for all tokenized terms including masked term_"
      ],
      "metadata": {
        "id": "j61NCxX2MXi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topk = DEFAULT_TOP_K\n",
        "patched = False\n",
        "threshold = ACCRUE_THRESHOLD\n",
        "#text = \"John flew from New York to [MASK]\"\n",
        "text = \"Parkinson who works for XCorp suffers from progressive [MASK]\"\n",
        "perform_task(model,tokenizer,topk,threshold,text,patched)"
      ],
      "metadata": {
        "id": "qqGEI0BNMTBD",
        "outputId": "f7a1626c-d452-48db-9c2c-e35edfc14878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Parkinson', 'who', 'works', 'for', 'X', '##Co', '##rp', 'suffer', '##s', 'from', 'progressive', '[MASK]', '[SEP]']\n",
            "********* Top predictions for token:  [CLS]\n",
            "surgery 7.5769\n",
            "who 7.3091\n",
            "Surgery 7.2822\n",
            "levodopa 6.9597\n",
            "of 6.9088\n",
            "Rehabilitation 6.6983\n",
            "and 6.6847\n",
            "Methods 6.683\n",
            "history 6.6558\n",
            "Currently 6.6367\n",
            "symptoms 6.5641\n",
            "one 6.4077\n",
            "Stroke 6.3296\n",
            "progresses 6.3196\n",
            "degeneration 6.2876\n",
            "20 6.2857\n",
            "waiting 6.2578\n",
            "Patients 6.2323\n",
            "PD 6.1677\n",
            "Motor 6.135\n",
            "One 6.1258\n",
            "********* Closest sentence neighbors in output to the token :   [CLS]\n",
            "who 7.3091\n",
            "Parkinson 5.6706\n",
            "progressive 5.531\n",
            "for 4.6574\n",
            "suffer 4.3762\n",
            "from 3.9757\n",
            "works 3.128\n",
            "\n",
            "\n",
            "********* Top predictions for token:  Parkinson\n",
            "Parkinson 15.0947\n",
            "Patients 14.5075\n",
            "Patient 13.7469\n",
            "Subject 13.0993\n",
            "Those 12.4626\n",
            "patient 12.395\n",
            "Participant 12.2981\n",
            "One 12.2895\n",
            "Individuals 11.9122\n",
            "Subjects 11.9035\n",
            "People 11.6763\n",
            "Participants 11.6334\n",
            "and 11.3784\n",
            "subject 11.249\n",
            "patients 10.8569\n",
            "or 10.671\n",
            "The 10.602\n",
            "Persons 10.394\n",
            "person 10.3795\n",
            "PD 10.1144\n",
            "Investigators 10.1098\n",
            "********* Closest sentence neighbors in output to the token :   Parkinson\n",
            "Parkinson 15.0947\n",
            "who 6.5332\n",
            "suffer 4.2737\n",
            "from 4.0432\n",
            "for 4.0332\n",
            "progressive 3.3459\n",
            "works 0.0032\n",
            "\n",
            "\n",
            "********* Top predictions for token:  who\n",
            "who 19.8865\n",
            "that 12.6074\n",
            "undergoing 11.0163\n",
            "patient 10.5351\n",
            "which 10.0387\n",
            "living 9.8063\n",
            "receiving 9.7862\n",
            "treated 9.6558\n",
            "on 9.5409\n",
            "currently 9.3071\n",
            "following 8.7932\n",
            "also 8.7781\n",
            "treatment 8.6437\n",
            "having 8.5826\n",
            "surgery 8.4466\n",
            "whom 8.3631\n",
            "patients 8.2675\n",
            "intervention 8.1465\n",
            "starting 8.1175\n",
            "diagnosed 8.1158\n",
            "then 8.1019\n",
            "********* Closest sentence neighbors in output to the token :   who\n",
            "who 19.8865\n",
            "from 5.2255\n",
            "progressive 4.2313\n",
            "suffer 4.0106\n",
            "for 3.0797\n",
            "Parkinson 1.4971\n",
            "works -0.9755\n",
            "\n",
            "\n",
            "********* Top predictions for token:  works\n",
            "works 17.3566\n",
            "work 11.6667\n",
            "screens 11.2108\n",
            "searches 11.1602\n",
            "used 10.8002\n",
            "treated 10.7986\n",
            "wait 10.2088\n",
            "does 10.1389\n",
            "uses 10.1292\n",
            "visits 9.9427\n",
            "stands 9.7902\n",
            "is 9.761\n",
            "performs 9.6075\n",
            "followed 9.5105\n",
            "search 9.4544\n",
            "hospitalized 9.3194\n",
            "functions 9.2454\n",
            "care 9.2426\n",
            "exists 9.2117\n",
            "sits 9.1747\n",
            "worked 9.1163\n",
            "********* Closest sentence neighbors in output to the token :   works\n",
            "works 17.3566\n",
            "suffer 6.5596\n",
            "who 5.3225\n",
            "for 4.354\n",
            "from 3.6235\n",
            "Parkinson 2.4615\n",
            "progressive 1.3923\n",
            "\n",
            "\n",
            "********* Top predictions for token:  for\n",
            "for 16.4356\n",
            "with 10.3197\n",
            "the 10.1904\n",
            "an 9.009\n",
            "without 8.7895\n",
            "For 8.2265\n",
            "after 8.0707\n",
            "in 8.037\n",
            "using 7.8164\n",
            "as 7.6644\n",
            "on 7.4994\n",
            "online 7.3366\n",
            "this 7.2532\n",
            "to 7.2398\n",
            "following 7.0235\n",
            "now 6.9573\n",
            "MRI 6.9382\n",
            "such 6.9183\n",
            "since 6.9105\n",
            "performing 6.855\n",
            "at 6.7921\n",
            "********* Closest sentence neighbors in output to the token :   for\n",
            "for 16.4356\n",
            "works 5.7117\n",
            "from 5.0125\n",
            "progressive 4.0459\n",
            "who 3.844\n",
            "suffer 1.6157\n",
            "Parkinson 0.2774\n",
            "\n",
            "\n",
            "********* Top predictions for token:  X\n",
            "XL 11.1635\n",
            "the 10.1996\n",
            "their 9.9401\n",
            "IX 9.3249\n",
            "XI 9.0413\n",
            "this 8.8222\n",
            "works 8.7856\n",
            "Ph 8.7425\n",
            "these 8.2244\n",
            "Radiation 8.1637\n",
            "its 8.124\n",
            "radiation 8.0881\n",
            "your 7.928\n",
            "every 7.8325\n",
            "TM 7.7969\n",
            "standard 7.747\n",
            "radiotherapy 7.7087\n",
            "Lin 7.6219\n",
            "daily 7.6002\n",
            "Daily 7.5155\n",
            "which 7.4564\n",
            "********* Closest sentence neighbors in output to the token :   X\n",
            "works 8.7856\n",
            "for 6.348\n",
            "progressive 3.4084\n",
            "from 3.2483\n",
            "who 2.4057\n",
            "Parkinson 0.1813\n",
            "suffer -0.5629\n",
            "\n",
            "\n",
            "********* Top predictions for token:  ##Co\n",
            "Gy 9.0562\n",
            "Co 8.2145\n",
            "lead 7.9579\n",
            "to 7.7956\n",
            "cobalt 7.7751\n",
            "cancer 7.454\n",
            "and 7.4294\n",
            "with 7.4174\n",
            "radiation 7.4099\n",
            "mission 7.3469\n",
            "will 7.2393\n",
            "first 7.1724\n",
            "works 7.1681\n",
            "Lin 7.1554\n",
            "Ph 7.0833\n",
            "exposure 7.0548\n",
            "therapy 7.016\n",
            "phone 6.9896\n",
            "treatment 6.9452\n",
            "burden 6.8185\n",
            "Me 6.7664\n",
            "********* Closest sentence neighbors in output to the token :   ##Co\n",
            "works 7.1681\n",
            "for 5.668\n",
            "who 3.5691\n",
            "from 3.5122\n",
            "suffer 3.471\n",
            "progressive 1.6335\n",
            "Parkinson -0.6481\n",
            "\n",
            "\n",
            "********* Top predictions for token:  ##rp\n",
            "treatment 11.0239\n",
            "therapy 10.6505\n",
            "weeks 9.7281\n",
            "and 9.2585\n",
            "radiation 9.2128\n",
            "exposure 9.0976\n",
            "months 8.9642\n",
            "years 8.8931\n",
            "patients 8.8621\n",
            "intervention 8.7379\n",
            "MRI 8.6588\n",
            "days 8.561\n",
            "phone 8.3852\n",
            "screening 8.3339\n",
            "rays 8.2683\n",
            "it 8.1873\n",
            "radiotherapy 8.1591\n",
            "hours 8.099\n",
            "year 8.0858\n",
            "implantation 8.0559\n",
            "replacement 8.0227\n",
            "********* Closest sentence neighbors in output to the token :   ##rp\n",
            "works 7.829\n",
            "who 6.9715\n",
            "for 5.2009\n",
            "from 3.0694\n",
            "suffer 0.9191\n",
            "progressive -0.5044\n",
            "Parkinson -0.6028\n",
            "\n",
            "\n",
            "********* Top predictions for token:  suffer\n",
            "suffer 26.7689\n",
            "suffering 19.2704\n",
            "suffered 16.6083\n",
            "complain 15.9008\n",
            "die 15.0528\n",
            "symptoms 13.3287\n",
            "starts 13.2492\n",
            "develops 13.0041\n",
            "It 12.7099\n",
            "develop 12.6501\n",
            "ends 12.3412\n",
            "subjects 11.9532\n",
            "comes 11.905\n",
            "arises 11.8869\n",
            "experiences 11.6074\n",
            "patients 11.5872\n",
            "often 11.5417\n",
            "experience 11.4599\n",
            "originates 11.3885\n",
            "exc 11.367\n",
            "or 11.3499\n",
            "********* Closest sentence neighbors in output to the token :   suffer\n",
            "suffer 26.7689\n",
            "who 10.1638\n",
            "for 5.9328\n",
            "from 5.3583\n",
            "works 5.3199\n",
            "progressive 4.0773\n",
            "Parkinson 1.9912\n",
            "\n",
            "\n",
            "********* Top predictions for token:  ##s\n",
            "is 16.9424\n",
            "has 15.5217\n",
            "subjects 14.8131\n",
            "patients 13.4083\n",
            "will 12.5008\n",
            "also 12.1502\n",
            "often 11.8888\n",
            "fluctuations 11.5316\n",
            "may 11.4874\n",
            "progresses 11.3172\n",
            "symptoms 11.2813\n",
            "does 11.1625\n",
            "presents 11.0355\n",
            "individuals 10.9176\n",
            "an 10.8563\n",
            "most 10.7977\n",
            "reports 10.6466\n",
            "cells 10.6279\n",
            "one 10.5558\n",
            "develops 10.3746\n",
            "from 10.2963\n",
            "********* Closest sentence neighbors in output to the token :   ##s\n",
            "from 10.2963\n",
            "who 8.3587\n",
            "suffer 8.3319\n",
            "progressive 6.9567\n",
            "Parkinson 5.3936\n",
            "for 4.8587\n",
            "works 4.4136\n",
            "\n",
            "\n",
            "********* Top predictions for token:  from\n",
            "from 20.3702\n",
            "in 11.9501\n",
            "have 10.2934\n",
            "severe 10.1475\n",
            "recurrent 9.5207\n",
            "clinical 9.429\n",
            "an 9.3335\n",
            "has 9.3267\n",
            "significant 9.0832\n",
            "by 8.9447\n",
            "the 8.8434\n",
            "significantly 8.7401\n",
            "heavily 8.7389\n",
            "highly 8.5611\n",
            "with 8.4306\n",
            "moderate 8.3486\n",
            "many 8.3242\n",
            "show 8.3002\n",
            "some 8.2117\n",
            "frequently 8.1195\n",
            "form 7.9819\n",
            "********* Closest sentence neighbors in output to the token :   from\n",
            "from 20.3702\n",
            "progressive 5.8206\n",
            "for 5.6203\n",
            "who 4.7953\n",
            "suffer 4.4431\n",
            "Parkinson 0.3182\n",
            "works -0.2331\n",
            "\n",
            "\n",
            "********* Top predictions for token:  progressive\n",
            "progressive 21.5522\n",
            "progression 17.3006\n",
            "progressing 14.8149\n",
            "deterior 12.9628\n",
            "progress 12.5469\n",
            "movement 12.2493\n",
            "deterioration 11.9575\n",
            "motor 11.8975\n",
            "severe 11.7572\n",
            "recurrent 11.7203\n",
            "slow 11.6271\n",
            "advanced 11.5452\n",
            "Progressive 11.3685\n",
            "chronic 11.2268\n",
            "disease 11.0403\n",
            "PD 10.9123\n",
            "significant 10.796\n",
            "relapsing 10.6522\n",
            "or 10.5583\n",
            "slowly 10.4602\n",
            "progressively 10.4117\n",
            "********* Closest sentence neighbors in output to the token :   progressive\n",
            "progressive 21.5522\n",
            "who 10.3678\n",
            "Parkinson 9.0135\n",
            "from 7.1058\n",
            "suffer 5.708\n",
            "for 4.7691\n",
            "works 0.107\n",
            "\n",
            "\n",
            "********* Top predictions for token:  [MASK]\n",
            "motor 11.8826\n",
            "disease 11.7671\n",
            "cognitive 11.5873\n",
            "Parkinson 11.564\n",
            "neurological 11.5082\n",
            "symptoms 11.4038\n",
            "progressive 10.869\n",
            "brain 10.7228\n",
            "neurologic 10.7027\n",
            "levodopa 10.5775\n",
            "parkinsonism 10.3276\n",
            "cerebellar 10.3226\n",
            "sensory 10.2257\n",
            "neurodegenerative 10.1953\n",
            "muscle 10.1725\n",
            "bilateral 10.1351\n",
            "gait 10.1202\n",
            "hand 10.0779\n",
            "dystonia 10.0537\n",
            "dementia 10.037\n",
            "dyskinesia 10.0239\n",
            "********* Closest sentence neighbors in output to the token :   [MASK]\n",
            "Parkinson 11.564\n",
            "progressive 10.869\n",
            "from 4.478\n",
            "suffer 2.6095\n",
            "for 2.4203\n",
            "who 1.6698\n",
            "works -0.9328\n",
            "\n",
            "\n",
            "********* Top predictions for token:  [SEP]\n",
            "with 7.6689\n",
            "to 7.4354\n",
            "in 7.3505\n",
            "growth 7.326\n",
            "the 7.049\n",
            "of 7.0098\n",
            "this 6.9502\n",
            "and 6.8212\n",
            "by 6.3136\n",
            "or 6.258\n",
            "years 6.1624\n",
            "both 6.1259\n",
            "changes 6.1078\n",
            "levels 6.0611\n",
            "results 6.055\n",
            "as 5.9511\n",
            "components 5.9474\n",
            "that 5.8785\n",
            "all 5.8673\n",
            "which 5.862\n",
            "based 5.8601\n",
            "********* Closest sentence neighbors in output to the token :   [SEP]\n",
            "for 5.5609\n",
            "from 5.5494\n",
            "works 1.875\n",
            "who 0.8092\n",
            "progressive -0.551\n",
            "Parkinson -1.432\n",
            "suffer -2.6365\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "test_notebook.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}